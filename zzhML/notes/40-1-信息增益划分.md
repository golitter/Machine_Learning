信息熵（entropy）是度量样本集合“纯度”最常用的一种指标。假定当前样本集合D中第k类样本所占的比例为$p_k$，则D的信息熵定义为：
$$
Ent(D) = - \sum_{k=1}^{|y|}p_klog{2p_k}
$$
Ent(D)的值越小，则D的纯度越高。

信息增益直接以信息熵为基础，计算当前划分对信息熵所造成的变化。

> 计算信息熵时约定：若p=0，则pklog2pk=0
>
> Ent(D)的最小值是0，最大值是$log_2|y|$

离散属性a的取值：${a^1...a^V}$

$D^V$：D中在a上取值 = $a^V$的样本集合。

![image-20241122154253452](40-1-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E5%88%92%E5%88%86.assets/image-20241122154253452.png)